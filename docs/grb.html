<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Gamma-Ray Bursts | Nilanjana Bagchi Aurpa</title>

  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Serif font -->
  <link href="https://fonts.googleapis.com/css2?family=EB+Garamond:ital,wght@0,400;1,400&display=swap" rel="stylesheet">

  <!-- Your main stylesheet -->
  <link rel="stylesheet" href="introstyle.css">
</head>

<body>
  <div class="page">

    <!-- ========== SIDEBAR ========== -->
    <aside class="sidebar">

      <div class="portrait-wrap">
        <img src="images/profile.jpg" alt="Portrait of Nilanjana Bagchi Aurpa" class="portrait">
      </div>

      <hr class="nav-rule">

      <nav class="nav">
        <a href="intro.html">Home</a>
        <a href="cosmology.html">Cosmology</a>
        <a href="grb.html" class="active">Gamma-Ray Bursts</a>
        <a href="fisher.html">Fisher Information</a>
        <a href="gaussian.html">Gaussian Processes</a>
      </nav>

    </aside>

    <!-- ========== MAIN CONTENT ========== -->
    <main class="content">

      <h1>Gamma-Ray Bursts</h1>

      <p class="meta">
        Observational astrophysics · spectral modeling · machine learning
      </p>

      <p>
        This project explores the use of neural networks for modeling GRB prompt emission spectra,
        with the aim of accelerating parameter inference compared to traditional forward-folding
        likelihood-based methods.
      </p>

      <h2>Neural Network Architecture</h2>

      <figure class="figure">
        <img src="images/nn_architecture.png" alt="Feed-forward neural network architecture diagram">
        <figcaption>
          <strong>Figure 1.</strong> Architecture of the feed-forward neural network used for spectral
          parameter regression. The network consists of an input layer corresponding to binned photon
          counts, followed by two hidden layers with nonlinear activations, and a single output neuron
          representing the inferred spectral parameter.
        </figcaption>
      </figure>

      <h2>Training Behaviour</h2>

      <figure class="figure">
        <img src="images/training_curve.png" alt="Training and validation loss curves">
        <figcaption>
          <strong>Figure 2.</strong> Training and validation loss as a function of epoch. Both curves
          converge smoothly, indicating stable optimization and no strong evidence of overfitting.
          Small-scale fluctuations arise due to stochastic mini-batch sampling.
        </figcaption>
      </figure>

      <h2>Model Performance</h2>

      <figure class="figure">
        <img src="images/pred_vs_true.png" alt="Predicted versus true parameter scatter plot">
        <figcaption>
          <strong>Figure 3.</strong> Comparison between predicted and true spectral parameters on the
          validation set. The diagonal line represents perfect agreement. Scatter about the diagonal
          reflects residual model uncertainty and degeneracies in the spectral shapes.
        </figcaption>
      </figure>

      <footer>
        <p>
          Code and trained models are available on GitHub.  
          For full technical details, see the associated arXiv preprint.
        </p>
      </footer>

    </main>

  </div>
</body>
</html>
